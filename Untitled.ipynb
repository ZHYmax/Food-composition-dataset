{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import torch.nn as nn\n",
    "import scipy.stats\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from resnet_dynamic import resnet50\n",
    "from resnet_prune_split import prune_both_True, prune_only_mid, prune_both_False, prune_first_conv\n",
    "from utils import result_output, resnet_hook\n",
    "from resnet_LRP_def import LRP\n",
    "import cv2\n",
    "resnet = resnet50()\n",
    "resnet.load_state_dict(torch.load('./resnet50-19c8e357.pth'))\n",
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(104) tensor(12.9166) 0.90440094\n",
      "tensor(331) tensor(10.3450) 0.069111586\n",
      "tensor(330) tensor(8.6037) 0.012115271\n",
      "tensor(674) tensor(6.3568) 0.0012809114\n",
      "tensor(363) tensor(6.1032) 0.000993968\n",
      " \n",
      "new bottleneck\n",
      "True True\n",
      "tensor(104) tensor(12.9166) 0.90440094\n",
      "tensor(331) tensor(10.3450) 0.069111586\n",
      "tensor(330) tensor(8.6037) 0.012115271\n",
      "tensor(674) tensor(6.3568) 0.0012809114\n",
      "tensor(363) tensor(6.1032) 0.000993968\n",
      " \n",
      "False False\n",
      "tensor(104) tensor(12.9166) 0.48533884\n",
      "tensor(331) tensor(12.5317) 0.330307\n",
      "tensor(330) tensor(11.5319) 0.12152834\n",
      "tensor(674) tensor(9.7154) 0.019760387\n",
      "tensor(353) tensor(8.4492) 0.0055707875\n",
      " \n",
      "False True\n",
      "tensor(104) tensor(12.9166) 0.95770377\n",
      "tensor(331) tensor(9.4168) 0.028926132\n",
      "tensor(330) tensor(7.2417) 0.0032860215\n",
      "tensor(363) tensor(5.7908) 0.00077014737\n",
      "tensor(332) tensor(5.4636) 0.00055520196\n",
      " \n",
      "KL_sc 0.62627244\n",
      "KL_md 0.023065709\n",
      " \n",
      "(1, 2048, 7, 7)\n",
      "tensor(986) tensor(4.6448) 0.03925351\n",
      "tensor(199) tensor(4.6228) 0.03839803\n",
      "tensor(351) tensor(4.5579) 0.035987467\n",
      "tensor(350) tensor(4.3359) 0.028823035\n",
      "tensor(287) tensor(4.2518) 0.02649612\n",
      " \n",
      "(1, 2048, 7, 7)\n",
      "tensor(350) tensor(5.6037) 0.11184243\n",
      "tensor(104) tensor(4.6174) 0.041714635\n",
      "tensor(989) tensor(4.1021) 0.024917405\n",
      "tensor(986) tensor(3.8917) 0.020189533\n",
      "tensor(351) tensor(3.8413) 0.019196067\n",
      " \n",
      "(1, 2048, 7, 7)\n",
      "tensor(104) tensor(6.1409) 0.12023261\n",
      "tensor(351) tensor(5.1651) 0.045311637\n",
      "tensor(906) tensor(5.0830) 0.041743234\n",
      "tensor(236) tensor(4.8718) 0.033793468\n",
      "tensor(350) tensor(4.7071) 0.02866341\n",
      " \n",
      "(1, 512, 7, 7)\n",
      "tensor(104) tensor(1.5394) 0.004257366\n",
      "tensor(183) tensor(1.3491) 0.0035193881\n",
      "tensor(681) tensor(1.3452) 0.0035056795\n",
      "tensor(287) tensor(1.3379) 0.003480132\n",
      "tensor(89) tensor(1.3213) 0.0034228468\n",
      " \n",
      "(1, 512, 14, 14)\n",
      "tensor(104) tensor(1.9821) 0.006400703\n",
      "tensor(952) tensor(1.7881) 0.0052719424\n",
      "tensor(986) tensor(1.6962) 0.004808736\n",
      "tensor(183) tensor(1.6290) 0.004496563\n",
      "tensor(459) tensor(1.5785) 0.0042751683\n",
      " \n",
      "new bottleneck\n",
      "True True\n",
      "tensor(104) tensor(12.9165) 0.47147778\n",
      "tensor(952) tensor(11.6523) 0.1331684\n",
      "tensor(986) tensor(11.0530) 0.07313657\n",
      "tensor(183) tensor(10.6156) 0.04722556\n",
      "tensor(459) tensor(10.2866) 0.033984974\n",
      " \n",
      "False False\n",
      "tensor(104) tensor(12.9166) 0.43474382\n",
      "tensor(952) tensor(11.8346) 0.14734802\n",
      "tensor(986) tensor(11.2429) 0.08154413\n",
      "tensor(183) tensor(10.7125) 0.04797766\n",
      "tensor(459) tensor(10.4721) 0.037723083\n",
      " \n",
      "False True\n",
      "tensor(104) tensor(12.9166) 0.42600778\n",
      "tensor(952) tensor(11.8743) 0.1502345\n",
      "tensor(986) tensor(11.2789) 0.082834154\n",
      "tensor(183) tensor(10.7577) 0.049187023\n",
      "tensor(459) tensor(10.4961) 0.037864972\n",
      " \n",
      "KL_sc 0.004199406\n",
      "KL_md 0.0061482564\n",
      " \n",
      "new bottleneck\n",
      "True True\n",
      "tensor(104) tensor(12.9166) 0.43474382\n",
      "tensor(952) tensor(11.8346) 0.14734802\n",
      "tensor(986) tensor(11.2429) 0.08154413\n",
      "tensor(183) tensor(10.7125) 0.04797766\n",
      "tensor(459) tensor(10.4721) 0.037723083\n",
      " \n",
      "False False\n",
      "tensor(104) tensor(12.9166) 0.40285522\n",
      "tensor(952) tensor(11.9829) 0.15837617\n",
      "tensor(986) tensor(11.3882) 0.087374926\n",
      "tensor(183) tensor(10.8296) 0.049979486\n",
      "tensor(459) tensor(10.5975) 0.039627094\n",
      " \n",
      "False True\n",
      "tensor(104) tensor(12.9166) 0.44645062\n",
      "tensor(952) tensor(11.7819) 0.14354356\n",
      "tensor(986) tensor(11.1724) 0.07803718\n",
      "tensor(183) tensor(10.6914) 0.048237316\n",
      "tensor(459) tensor(10.4045) 0.03620648\n",
      " \n",
      "KL_sc 0.0029451437\n",
      "KL_md 0.00049745385\n",
      " \n",
      "(1, 2048, 7, 7)\n",
      "[[1735, 313, 810, 702, 1222], [1299, 708, 289, 1737, 945, 1831], [1655, 942, 859, 472, 267], [771, 824, 1304, 250]]\n",
      "new bottleneck\n",
      "True True\n",
      "tensor(104) tensor(12.9166) 0.46682096\n",
      "tensor(952) tensor(11.6591) 0.1327536\n",
      "tensor(986) tensor(10.8970) 0.061954442\n",
      "tensor(183) tensor(10.7909) 0.055719897\n",
      "tensor(134) tensor(10.2042) 0.030988345\n",
      " \n",
      "False False\n",
      "tensor(104) tensor(12.9166) 0.4844605\n",
      "tensor(952) tensor(11.5537) 0.1239835\n",
      "tensor(183) tensor(10.7653) 0.056359816\n",
      "tensor(986) tensor(10.7649) 0.05633913\n",
      "tensor(134) tensor(10.1633) 0.030870529\n",
      " \n",
      "False True\n",
      "tensor(104) tensor(12.9166) 0.4339366\n",
      "tensor(952) tensor(11.8428) 0.14828506\n",
      "tensor(986) tensor(11.1568) 0.07467299\n",
      "tensor(183) tensor(10.8253) 0.053606324\n",
      "tensor(459) tensor(10.3421) 0.033065546\n",
      " \n",
      "KL_sc 0.0016838014\n",
      "KL_md 0.006327294\n",
      " \n",
      "new bottleneck\n",
      "True True\n",
      "tensor(104) tensor(12.9166) 0.4844605\n",
      "tensor(952) tensor(11.5537) 0.1239835\n",
      "tensor(183) tensor(10.7653) 0.056359816\n",
      "tensor(986) tensor(10.7649) 0.05633913\n",
      "tensor(134) tensor(10.1633) 0.030870529\n",
      " \n",
      "False False\n",
      "tensor(104) tensor(12.9166) 0.47946784\n",
      "tensor(952) tensor(11.5828) 0.1263329\n",
      "tensor(986) tensor(10.7971) 0.05758288\n",
      "tensor(183) tensor(10.7751) 0.056329224\n",
      "tensor(134) tensor(10.1749) 0.030909702\n",
      " \n",
      "False True\n",
      "tensor(104) tensor(12.9166) 0.43803176\n",
      "tensor(952) tensor(11.8218) 0.14657764\n",
      "tensor(986) tensor(11.1109) 0.07199721\n",
      "tensor(183) tensor(10.8304) 0.054389745\n",
      "tensor(459) tensor(10.3011) 0.032034755\n",
      " \n",
      "KL_sc 0.00011216616\n",
      "KL_md 0.011781655\n",
      " \n",
      "new bottleneck\n",
      "True True\n",
      "tensor(104) tensor(12.9166) 0.47946784\n",
      "tensor(952) tensor(11.5828) 0.1263329\n",
      "tensor(986) tensor(10.7971) 0.05758288\n",
      "tensor(183) tensor(10.7751) 0.056329224\n",
      "tensor(134) tensor(10.1749) 0.030909702\n",
      " \n",
      "False False\n",
      "tensor(104) tensor(12.9166) 0.4974076\n",
      "tensor(952) tensor(11.4695) 0.11701671\n",
      "tensor(183) tensor(10.7482) 0.0568893\n",
      "tensor(986) tensor(10.6592) 0.052039877\n",
      "tensor(906) tensor(10.2197) 0.033533365\n",
      " \n",
      "False True\n",
      "tensor(104) tensor(12.9166) 0.4290602\n",
      "tensor(952) tensor(11.8684) 0.15042783\n",
      "tensor(986) tensor(11.1675) 0.07463354\n",
      "tensor(183) tensor(10.8436) 0.05398195\n",
      "tensor(287) tensor(10.3641) 0.033420704\n",
      " \n",
      "KL_sc 0.0018457742\n",
      "KL_md 0.013584439\n",
      " \n",
      "new bottleneck\n",
      "True True\n",
      "tensor(104) tensor(12.9166) 0.4974076\n",
      "tensor(952) tensor(11.4695) 0.11701671\n",
      "tensor(183) tensor(10.7482) 0.0568893\n",
      "tensor(986) tensor(10.6592) 0.052039877\n",
      "tensor(906) tensor(10.2197) 0.033533365\n",
      " \n",
      "False False\n",
      "tensor(104) tensor(12.9166) 0.48707962\n",
      "tensor(952) tensor(11.5419) 0.12319742\n",
      "tensor(986) tensor(10.7695) 0.05690203\n",
      "tensor(183) tensor(10.7539) 0.0560223\n",
      "tensor(134) tensor(10.1561) 0.03081528\n",
      " \n",
      "False True\n",
      "tensor(104) tensor(12.9165) 0.4533196\n",
      "tensor(952) tensor(11.7311) 0.13853765\n",
      "tensor(986) tensor(10.9730) 0.064912036\n",
      "tensor(183) tensor(10.8242) 0.055937983\n",
      "tensor(134) tensor(10.2190) 0.030540228\n",
      " \n",
      "KL_sc 0.001161533\n",
      "KL_md 0.010274041\n",
      " \n",
      "new bottleneck\n",
      "True True\n",
      "tensor(104) tensor(12.9166) 0.48707962\n",
      "tensor(952) tensor(11.5419) 0.12319742\n",
      "tensor(986) tensor(10.7695) 0.05690203\n",
      "tensor(183) tensor(10.7539) 0.0560223\n",
      "tensor(134) tensor(10.1561) 0.03081528\n",
      " \n",
      "False False\n",
      "tensor(104) tensor(12.9166) 0.50298786\n",
      "tensor(952) tensor(11.4466) 0.11565819\n",
      "tensor(183) tensor(10.7216) 0.056014426\n",
      "tensor(986) tensor(10.6729) 0.053352833\n",
      "tensor(134) tensor(10.1126) 0.030466164\n",
      " \n",
      "False True\n",
      "tensor(104) tensor(12.9166) 0.44497073\n",
      "tensor(952) tensor(11.7827) 0.143191\n",
      "tensor(986) tensor(11.0610) 0.069577254\n",
      "tensor(183) tensor(10.8225) 0.05481364\n",
      "tensor(459) tensor(10.2520) 0.030984802\n",
      " \n",
      "KL_sc 0.0010710731\n",
      "KL_md 0.008779025\n",
      " \n",
      "new bottleneck\n",
      "True True\n",
      "tensor(104) tensor(12.9166) 0.50298786\n",
      "tensor(952) tensor(11.4466) 0.11565819\n",
      "tensor(183) tensor(10.7216) 0.056014426\n",
      "tensor(986) tensor(10.6729) 0.053352833\n",
      "tensor(134) tensor(10.1126) 0.030466164\n",
      " \n",
      "False False\n",
      "tensor(104) tensor(12.9166) 0.46143273\n",
      "tensor(952) tensor(11.6925) 0.13568334\n",
      "tensor(986) tensor(10.9606) 0.06526221\n",
      "tensor(183) tensor(10.7933) 0.05520907\n",
      "tensor(134) tensor(10.2073) 0.030726776\n",
      " \n",
      "False True\n",
      "tensor(104) tensor(12.9166) 0.47840047\n",
      "tensor(952) tensor(11.5984) 0.12803607\n",
      "tensor(986) tensor(10.8642) 0.061443213\n",
      "tensor(183) tensor(10.7572) 0.055208705\n",
      "tensor(134) tensor(10.1709) 0.03071506\n",
      " \n",
      "KL_sc 0.008510178\n",
      "KL_md 0.00348101\n",
      " \n",
      "(1, 1024, 14, 14)\n",
      "[[608], [1021, 929, 54, 487, 185, 596, 832, 114, 863, 590, 175], [591, 333, 626], [724, 661, 361, 444, 492]]\n",
      "new bottleneck\n",
      "True True\n",
      "tensor(104) tensor(12.9166) 0.572622\n",
      "tensor(952) tensor(10.9216) 0.07788747\n",
      "tensor(183) tensor(10.5589) 0.054192044\n",
      "tensor(906) tensor(10.3995) 0.046209157\n",
      "tensor(986) tensor(10.0304) 0.031947214\n",
      " \n",
      "False False\n",
      "tensor(104) tensor(12.9166) 0.5804182\n",
      "tensor(952) tensor(10.8607) 0.07428743\n",
      "tensor(183) tensor(10.5303) 0.053384904\n",
      "tensor(906) tensor(10.3894) 0.04636573\n",
      "tensor(986) tensor(9.9695) 0.03046791\n",
      " \n",
      "False True\n",
      "tensor(104) tensor(12.9166) 0.54107606\n",
      "tensor(952) tensor(11.1637) 0.093759514\n",
      "tensor(183) tensor(10.6602) 0.05667036\n",
      "tensor(906) tensor(10.3608) 0.042005494\n",
      "tensor(986) tensor(10.2994) 0.039502494\n",
      " \n",
      "KL_sc 0.00034559797\n",
      "KL_md 0.00636968\n",
      " \n",
      "new bottleneck\n",
      "True True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(104) tensor(12.9166) 0.5804182\n",
      "tensor(952) tensor(10.8607) 0.07428743\n",
      "tensor(183) tensor(10.5303) 0.053384904\n",
      "tensor(906) tensor(10.3894) 0.04636573\n",
      "tensor(986) tensor(9.9695) 0.03046791\n",
      " \n",
      "False False\n",
      "tensor(104) tensor(12.9165) 0.5829304\n",
      "tensor(952) tensor(10.8390) 0.07300712\n",
      "tensor(183) tensor(10.5210) 0.05312044\n",
      "tensor(906) tensor(10.3919) 0.046684064\n",
      "tensor(986) tensor(9.9458) 0.029882671\n",
      " \n",
      "False True\n",
      "tensor(104) tensor(12.9166) 0.5514183\n",
      "tensor(952) tensor(11.0806) 0.08793418\n",
      "tensor(183) tensor(10.6346) 0.056290433\n",
      "tensor(906) tensor(10.3978) 0.04442302\n",
      "tensor(986) tensor(10.2014) 0.036501814\n",
      " \n",
      "KL_sc 4.7829235e-05\n",
      "KL_md 0.0048387107\n",
      " \n",
      "new bottleneck\n",
      "True True\n",
      "tensor(104) tensor(12.9165) 0.5829304\n",
      "tensor(952) tensor(10.8390) 0.07300712\n",
      "tensor(183) tensor(10.5210) 0.05312044\n",
      "tensor(906) tensor(10.3919) 0.046684064\n",
      "tensor(986) tensor(9.9458) 0.029882671\n",
      " \n",
      "False False\n",
      "tensor(104) tensor(12.9166) 0.5800227\n",
      "tensor(952) tensor(10.8593) 0.0741263\n",
      "tensor(183) tensor(10.5334) 0.05351061\n",
      "tensor(906) tensor(10.4034) 0.046988446\n",
      "tensor(986) tensor(9.9640) 0.030280963\n",
      " \n",
      "False True\n",
      "tensor(104) tensor(12.9166) 0.55700064\n",
      "tensor(952) tensor(11.0433) 0.08556582\n",
      "tensor(183) tensor(10.6145) 0.055729315\n",
      "tensor(906) tensor(10.3861) 0.04435\n",
      "tensor(986) tensor(10.1652) 0.035559334\n",
      " \n",
      "KL_sc 3.808376e-05\n",
      "KL_md 0.0042000376\n",
      " \n",
      "new bottleneck\n",
      "True True\n",
      "tensor(104) tensor(12.9166) 0.5800227\n",
      "tensor(952) tensor(10.8593) 0.0741263\n",
      "tensor(183) tensor(10.5334) 0.05351061\n",
      "tensor(906) tensor(10.4034) 0.046988446\n",
      "tensor(986) tensor(9.9640) 0.030280963\n",
      " \n",
      "False False\n",
      "tensor(104) tensor(12.9166) 0.576515\n",
      "tensor(952) tensor(10.8816) 0.07534186\n",
      "tensor(183) tensor(10.5454) 0.053833\n",
      "tensor(906) tensor(10.4289) 0.047908977\n",
      "tensor(986) tensor(9.9783) 0.030531514\n",
      " \n",
      "False True\n",
      "tensor(104) tensor(12.9166) 0.5461471\n",
      "tensor(952) tensor(11.1231) 0.090872034\n",
      "tensor(183) tensor(10.6486) 0.05654024\n",
      "tensor(906) tensor(10.3797) 0.043208797\n",
      "tensor(986) tensor(10.2515) 0.038010146\n",
      " \n",
      "KL_sc 5.242345e-05\n",
      "KL_md 0.0072767325\n",
      " \n",
      "(1, 512, 28, 28)\n",
      "[[176, 412, 163, 161, 371], [357, 184, 317, 443, 54, 382, 110, 474, 511, 263, 217], [347], [388, 115, 349]]\n",
      "new bottleneck\n",
      "True True\n",
      "tensor(104) tensor(12.9166) 0.60882276\n",
      "tensor(952) tensor(10.6129) 0.060817655\n",
      "tensor(906) tensor(10.3973) 0.049021464\n",
      "tensor(183) tensor(10.3933) 0.04882685\n",
      "tensor(134) tensor(9.7980) 0.026921684\n",
      " \n",
      "False False\n",
      "tensor(104) tensor(12.9166) 0.6085129\n",
      "tensor(952) tensor(10.6133) 0.06081134\n",
      "tensor(906) tensor(10.4044) 0.049348544\n",
      "tensor(183) tensor(10.3941) 0.04883892\n",
      "tensor(134) tensor(9.7994) 0.0269465\n",
      " \n",
      "False True\n",
      "tensor(104) tensor(12.9166) 0.5888025\n",
      "tensor(952) tensor(10.7509) 0.06752267\n",
      "tensor(906) tensor(10.5407) 0.05471856\n",
      "tensor(183) tensor(10.4724) 0.05110736\n",
      "tensor(134) tensor(9.8886) 0.028505355\n",
      " \n",
      "KL_sc 1.5650585e-06\n",
      "KL_md 0.0019102413\n",
      " \n",
      "new bottleneck\n",
      "True True\n",
      "tensor(104) tensor(12.9166) 0.6085129\n",
      "tensor(952) tensor(10.6133) 0.06081134\n",
      "tensor(906) tensor(10.4044) 0.049348544\n",
      "tensor(183) tensor(10.3941) 0.04883892\n",
      "tensor(134) tensor(9.7994) 0.0269465\n",
      " \n",
      "False False\n",
      "tensor(104) tensor(12.9166) 0.6090383\n",
      "tensor(952) tensor(10.6049) 0.060357098\n",
      "tensor(906) tensor(10.4178) 0.050053876\n",
      "tensor(183) tensor(10.3878) 0.048578463\n",
      "tensor(134) tensor(9.8018) 0.027034556\n",
      " \n",
      "False True\n",
      "tensor(104) tensor(12.9166) 0.58760864\n",
      "tensor(952) tensor(10.7614) 0.06809878\n",
      "tensor(906) tensor(10.5373) 0.05442663\n",
      "tensor(183) tensor(10.4800) 0.05139332\n",
      "tensor(134) tensor(9.8898) 0.028484367\n",
      " \n",
      "KL_sc 1.6286518e-05\n",
      "KL_md 0.0020824475\n",
      " \n",
      "new bottleneck\n",
      "True True\n",
      "tensor(104) tensor(12.9166) 0.6090383\n",
      "tensor(952) tensor(10.6049) 0.060357098\n",
      "tensor(906) tensor(10.4178) 0.050053876\n",
      "tensor(183) tensor(10.3878) 0.048578463\n",
      "tensor(134) tensor(9.8018) 0.027034556\n",
      " \n",
      "False False\n",
      "tensor(104) tensor(12.9166) 0.600881\n",
      "tensor(952) tensor(10.6582) 0.06280311\n",
      "tensor(906) tensor(10.4862) 0.052880373\n",
      "tensor(183) tensor(10.4210) 0.04954102\n",
      "tensor(134) tensor(9.8390) 0.027684473\n",
      " \n",
      "False True\n",
      "tensor(104) tensor(12.9166) 0.5905954\n",
      "tensor(952) tensor(10.7471) 0.0674679\n",
      "tensor(906) tensor(10.4985) 0.052621424\n",
      "tensor(183) tensor(10.4714) 0.05121436\n",
      "tensor(134) tensor(9.8735) 0.028166085\n",
      " \n",
      "KL_sc 0.00031351857\n",
      "KL_md 0.0017555617\n",
      " \n",
      "(1, 256, 56, 56)\n",
      "[[220, 223, 251, 73], [143, 113, 187, 188, 189, 80, 241, 102, 186, 141, 167, 195, 8], [149], [215, 35]]\n",
      "(1, 64, 112, 112)\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 15, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(15, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(15, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(20, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(20, 20, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(20, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(20, 20, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(20, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(20, 20, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(20, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=100, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    tran = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                transforms.ToTensor(),\n",
    "                                # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                               ])\n",
    "    im = '../testModel/kangaroo.jpg'\n",
    "    im = Image.open(im)\n",
    "    im = tran(im)\n",
    "    im.unsqueeze_(dim=0)\n",
    "    select_list_reserve = [[[True,True],[True,True],[True,True],],[[True,True],[True,True],[True,True],[True,True],],[[True,True],[True,True],[True,True],[True,True],[True,True],[True,True],],[[True,True],[True,True],[True,True],]]\n",
    "    select_list = [[[True,True],[True,True],[True,True],],[[True,True],[True,True],[True,True],[True,True],],[[True,True],[True,True],[True,True],[True,True],[True,True],[True,True],],[[True,True],[True,True],[True,True],]]\n",
    "\n",
    "    out = resnet(im,select_list)\n",
    "    result_output(out)\n",
    "\n",
    "    feature_num = 15\n",
    "    cluster_num = 3\n",
    "    layer_list = [resnet.layer1, resnet.layer2, resnet.layer3, resnet.layer4]\n",
    "\n",
    "    for layer_index in range(3,-1,-1):#layer_index 从3 到 0\n",
    "        for bottleneck_index in range(len(layer_list[layer_index])-1,-1,-1):#bottlenet_index 从后到前\n",
    "            print('new bottleneck')\n",
    "            print('True True')\n",
    "            select_list[layer_index][bottleneck_index] = [True, True]\n",
    "            out = resnet(im, select_list)\n",
    "            if layer_index == 3 and bottleneck_index == 2:\n",
    "                out_origin = out\n",
    "            else:\n",
    "                out = out/(torch.max(out)/torch.max(out_origin))\n",
    "            out_probability = F.softmax(out, dim=1)\n",
    "            out_probability_np_both_True = out_probability.data[0].numpy()\n",
    "            # print(out_probability_np_both_True)\n",
    "            if layer_index==3 and bottleneck_index==2:\n",
    "                original_both_true = out_probability_np_both_True\n",
    "                ind_origin = result_output(out)\n",
    "            else:\n",
    "                ind1 = result_output(out)\n",
    "\n",
    "            print('False False')\n",
    "            select_list[layer_index][bottleneck_index] = [False, False]\n",
    "            out = resnet(im, select_list)\n",
    "            out = out / (torch.max(out) / torch.max(out_origin))\n",
    "            out_probability = F.softmax(out, dim=1)\n",
    "            out_probability_np_False_False = out_probability.data[0].numpy()\n",
    "            ind2 = result_output(out)\n",
    "\n",
    "            print('False True')\n",
    "            select_list[layer_index][bottleneck_index] = [False, True]\n",
    "            out = resnet(im, select_list)\n",
    "            out = out / (torch.max(out) / torch.max(out_origin))\n",
    "            out_probability = F.softmax(out, dim=1)\n",
    "            out_probability_np_False_True = out_probability.data[0].numpy()\n",
    "            ind3 = result_output(out)\n",
    "\n",
    "            KL_sc = scipy.stats.entropy(out_probability_np_False_False, out_probability_np_both_True)  # 这个大说明shortcut比例较小，中间层发挥了作用\n",
    "            KL_md = scipy.stats.entropy(out_probability_np_False_True, out_probability_np_both_True)  # 这个大说明shortcut比例大\n",
    "            print(\"KL_sc\",KL_sc)\n",
    "            print(\"KL_md\",KL_md)\n",
    "            print(\" \")\n",
    "\n",
    "            # KL_sc = 3\n",
    "            # KL_md = 1\n",
    "\n",
    "            if KL_sc < 0.3 and ind2 == ind_origin:\n",
    "                select_list_reserve[layer_index][bottleneck_index] = [False, False]\n",
    "                # 直接prune\n",
    "                if bottleneck_index == 0:\n",
    "                    select_list[layer_index][bottleneck_index] = [False, False]\n",
    "                else:\n",
    "                    del select_list[layer_index][bottleneck_index]\n",
    "                resnet = prune_both_False(resnet, im, layer_index, bottleneck_index, select_list)\n",
    "            elif KL_md < 0.5 and ind3 == ind_origin:\n",
    "                select_list_reserve[layer_index][bottleneck_index] = [False, True]\n",
    "                select_list[layer_index][bottleneck_index] = [False, True]\n",
    "                resnet = prune_only_mid(resnet, im, layer_index, bottleneck_index, select_list, cluster_num, feature_num, ind_origin)\n",
    "            else:\n",
    "                select_list_reserve[layer_index][bottleneck_index] = [True, True]\n",
    "                select_list[layer_index][bottleneck_index] = [True, True]\n",
    "                resnet = prune_both_True(resnet, im, layer_index, bottleneck_index, select_list, cluster_num, feature_num, ind_origin)\n",
    "\n",
    "    resnet = prune_first_conv(resnet, im, select_list, cluster_num, feature_num)\n",
    "    print(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[False, False], [False, False], [False, False]], [[False, False], [False, False], [False, False], [False, False]], [[False, False], [False, False], [False, False], [False, False], [False, False], [False, False]], [[False, False], [False, False], [False, True]]]\n",
      "tensor(104) tensor(2.4808) 0.009915468\n",
      "tensor(906) tensor(1.9919) 0.0060813217\n",
      "tensor(952) tensor(1.9713) 0.005956924\n",
      "tensor(183) tensor(1.9509) 0.0058371057\n",
      "tensor(134) tensor(1.8616) 0.005338374\n",
      " \n",
      "(224, 224, 3)\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(select_list_reserve)\n",
    "out = resnet(im,select_list)\n",
    "ind = result_output(out)\n",
    "resnet_hook(resnet)\n",
    "R_list, R_sc_list = LRP(resnet, im, select_list)\n",
    "R = R_list[0][1]\n",
    "R = R.squeeze()\n",
    "R = R.permute((1,2,0))\n",
    "R = R.data.numpy()\n",
    "# R = R[:,:,::-1]\n",
    "R = (R-R.min())/(R.max()-R.min())\n",
    "print(R.shape)\n",
    "numpy.savetxt('R.txt', R[:,:,0])\n",
    "# plt.imshow(R)\n",
    "# plt.show()\n",
    "print(R.max())\n",
    "print(R.min())\n",
    "# for i in range(100):\n",
    "#     R1 = R * (200+i)\n",
    "#     cv2.imshow('LRP'+str(i), R1)\n",
    "# R = R * 255\n",
    "\n",
    "# # print(R)\n",
    "# R = R\n",
    "cv2.imshow('LRP', R)\n",
    "# R = R*1000\n",
    "# cv2.imshow('origin',im.squeeze().permute(1,2,0).data.numpy()[:,:,::-1] )\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",,,\n",
      "torch.Size([1, 20, 7, 7])\n",
      ",,,\n",
      "torch.Size([1, 20, 14, 14])\n",
      ",,,\n",
      "torch.Size([1, 20, 28, 28])\n",
      ",,,\n",
      "torch.Size([1, 20, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "for i in R_sc_list:\n",
    "    print(\",,,\")\n",
    "    for j in i:\n",
    "        print(j.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.00117896]\n",
      "  [0.00174814]\n",
      "  [0.00152573]\n",
      "  [0.00152451]\n",
      "  [0.00152893]\n",
      "  [0.00176122]\n",
      "  [0.00131873]]\n",
      "\n",
      " [[0.00171337]\n",
      "  [0.00253177]\n",
      "  [0.00220715]\n",
      "  [0.00221218]\n",
      "  [0.00221138]\n",
      "  [0.00259655]\n",
      "  [0.00184909]]\n",
      "\n",
      " [[0.00146665]\n",
      "  [0.00217604]\n",
      "  [0.00188543]\n",
      "  [0.00189655]\n",
      "  [0.00188929]\n",
      "  [0.00222812]\n",
      "  [0.00160179]]\n",
      "\n",
      " [[0.00146406]\n",
      "  [0.00218048]\n",
      "  [0.00188849]\n",
      "  [0.00188436]\n",
      "  [0.00188771]\n",
      "  [0.00223877]\n",
      "  [0.00159619]]\n",
      "\n",
      " [[0.00147071]\n",
      "  [0.0021932 ]\n",
      "  [0.00188472]\n",
      "  [0.0018937 ]\n",
      "  [0.00189791]\n",
      "  [0.0022261 ]\n",
      "  [0.00159942]]\n",
      "\n",
      " [[0.0016782 ]\n",
      "  [0.00252849]\n",
      "  [0.00218619]\n",
      "  [0.0021878 ]\n",
      "  [0.002186  ]\n",
      "  [0.00260454]\n",
      "  [0.00192302]]\n",
      "\n",
      " [[0.00128997]\n",
      "  [0.00186641]\n",
      "  [0.00163485]\n",
      "  [0.00163606]\n",
      "  [0.00164214]\n",
      "  [0.00198457]\n",
      "  [0.00144277]]]\n"
     ]
    }
   ],
   "source": [
    "filter_image = R_sc_list[0][-1][0,10:11,:,:].permute((1,2,0))\n",
    "filter_image = filter_image.data.numpy()\n",
    "print((filter_image))\n",
    "filter_image = (filter_image-filter_image.min())/(filter_image.max()-filter_image.min())\n",
    "print(filter_image)\n",
    "cv2.imshow('LRP', filter_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5823, 0.5821, 0.5819,  ..., 0.5808, 0.5786, 0.5767],\n",
      "          [0.5838, 0.5827, 0.5835,  ..., 0.5827, 0.5812, 0.5791],\n",
      "          [0.5831, 0.5835, 0.5832,  ..., 0.5836, 0.5830, 0.5798],\n",
      "          ...,\n",
      "          [0.5788, 0.5784, 0.5804,  ..., 0.5783, 0.5782, 0.5780],\n",
      "          [0.5786, 0.5789, 0.5809,  ..., 0.5793, 0.5791, 0.5783],\n",
      "          [0.5796, 0.5781, 0.5790,  ..., 0.5801, 0.5786, 0.5781]],\n",
      "\n",
      "         [[0.5823, 0.5821, 0.5819,  ..., 0.5808, 0.5786, 0.5767],\n",
      "          [0.5838, 0.5827, 0.5835,  ..., 0.5827, 0.5812, 0.5791],\n",
      "          [0.5831, 0.5835, 0.5832,  ..., 0.5836, 0.5830, 0.5798],\n",
      "          ...,\n",
      "          [0.5788, 0.5784, 0.5804,  ..., 0.5783, 0.5782, 0.5780],\n",
      "          [0.5786, 0.5789, 0.5809,  ..., 0.5793, 0.5791, 0.5783],\n",
      "          [0.5796, 0.5781, 0.5790,  ..., 0.5801, 0.5786, 0.5781]],\n",
      "\n",
      "         [[0.5823, 0.5821, 0.5819,  ..., 0.5808, 0.5786, 0.5767],\n",
      "          [0.5838, 0.5827, 0.5835,  ..., 0.5827, 0.5812, 0.5791],\n",
      "          [0.5831, 0.5835, 0.5832,  ..., 0.5836, 0.5830, 0.5798],\n",
      "          ...,\n",
      "          [0.5788, 0.5784, 0.5804,  ..., 0.5783, 0.5782, 0.5780],\n",
      "          [0.5786, 0.5789, 0.5809,  ..., 0.5793, 0.5791, 0.5783],\n",
      "          [0.5796, 0.5781, 0.5790,  ..., 0.5801, 0.5786, 0.5781]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.5823, 0.5821, 0.5819,  ..., 0.5808, 0.5786, 0.5767],\n",
      "          [0.5838, 0.5827, 0.5835,  ..., 0.5827, 0.5812, 0.5791],\n",
      "          [0.5831, 0.5835, 0.5832,  ..., 0.5836, 0.5830, 0.5798],\n",
      "          ...,\n",
      "          [0.5788, 0.5784, 0.5804,  ..., 0.5783, 0.5782, 0.5780],\n",
      "          [0.5786, 0.5789, 0.5809,  ..., 0.5793, 0.5791, 0.5783],\n",
      "          [0.5796, 0.5781, 0.5790,  ..., 0.5801, 0.5786, 0.5781]],\n",
      "\n",
      "         [[0.5823, 0.5821, 0.5819,  ..., 0.5808, 0.5786, 0.5767],\n",
      "          [0.5838, 0.5827, 0.5835,  ..., 0.5827, 0.5812, 0.5791],\n",
      "          [0.5831, 0.5835, 0.5832,  ..., 0.5836, 0.5830, 0.5798],\n",
      "          ...,\n",
      "          [0.5788, 0.5784, 0.5804,  ..., 0.5783, 0.5782, 0.5780],\n",
      "          [0.5786, 0.5789, 0.5809,  ..., 0.5793, 0.5791, 0.5783],\n",
      "          [0.5796, 0.5781, 0.5790,  ..., 0.5801, 0.5786, 0.5781]],\n",
      "\n",
      "         [[0.5823, 0.5821, 0.5819,  ..., 0.5808, 0.5786, 0.5767],\n",
      "          [0.5838, 0.5827, 0.5835,  ..., 0.5827, 0.5812, 0.5791],\n",
      "          [0.5831, 0.5835, 0.5832,  ..., 0.5836, 0.5830, 0.5798],\n",
      "          ...,\n",
      "          [0.5788, 0.5784, 0.5804,  ..., 0.5783, 0.5782, 0.5780],\n",
      "          [0.5786, 0.5789, 0.5809,  ..., 0.5793, 0.5791, 0.5783],\n",
      "          [0.5796, 0.5781, 0.5790,  ..., 0.5801, 0.5786, 0.5781]]]],\n",
      "       grad_fn=<ThresholdBackward1>)\n",
      "tensor([[[[0.2281, 0.2279, 0.2292, 0.2287, 0.2292, 0.2286, 0.2266],\n",
      "          [0.2284, 0.2285, 0.2285, 0.2290, 0.2287, 0.2283, 0.2284],\n",
      "          [0.2276, 0.2279, 0.2266, 0.2284, 0.2272, 0.2284, 0.2275],\n",
      "          [0.2276, 0.2286, 0.2272, 0.2260, 0.2266, 0.2282, 0.2265],\n",
      "          [0.2278, 0.2292, 0.2274, 0.2277, 0.2284, 0.2259, 0.2268],\n",
      "          [0.2271, 0.2272, 0.2265, 0.2259, 0.2255, 0.2253, 0.2270],\n",
      "          [0.2266, 0.2275, 0.2266, 0.2266, 0.2277, 0.2271, 0.2268]],\n",
      "\n",
      "         [[0.2050, 0.2047, 0.2056, 0.2055, 0.2059, 0.2057, 0.2041],\n",
      "          [0.2052, 0.2052, 0.2054, 0.2058, 0.2057, 0.2055, 0.2052],\n",
      "          [0.2046, 0.2048, 0.2048, 0.2058, 0.2051, 0.2052, 0.2043],\n",
      "          [0.2043, 0.2050, 0.2049, 0.2045, 0.2047, 0.2056, 0.2035],\n",
      "          [0.2049, 0.2058, 0.2045, 0.2052, 0.2055, 0.2044, 0.2036],\n",
      "          [0.2042, 0.2043, 0.2037, 0.2036, 0.2034, 0.2031, 0.2038],\n",
      "          [0.2036, 0.2043, 0.2037, 0.2038, 0.2043, 0.2042, 0.2037]],\n",
      "\n",
      "         [[0.0402, 0.0402, 0.0404, 0.0403, 0.0404, 0.0403, 0.0400],\n",
      "          [0.0403, 0.0402, 0.0403, 0.0404, 0.0403, 0.0403, 0.0403],\n",
      "          [0.0401, 0.0402, 0.0400, 0.0403, 0.0401, 0.0402, 0.0401],\n",
      "          [0.0401, 0.0403, 0.0401, 0.0400, 0.0400, 0.0403, 0.0399],\n",
      "          [0.0402, 0.0404, 0.0401, 0.0402, 0.0403, 0.0399, 0.0400],\n",
      "          [0.0400, 0.0401, 0.0399, 0.0399, 0.0398, 0.0398, 0.0400],\n",
      "          [0.0399, 0.0401, 0.0400, 0.0400, 0.0401, 0.0400, 0.0400]],\n",
      "\n",
      "         [[0.3159, 0.3156, 0.3167, 0.3166, 0.3171, 0.3167, 0.3148],\n",
      "          [0.3162, 0.3162, 0.3164, 0.3169, 0.3168, 0.3165, 0.3162],\n",
      "          [0.3154, 0.3157, 0.3155, 0.3168, 0.3160, 0.3162, 0.3151],\n",
      "          [0.3152, 0.3161, 0.3157, 0.3151, 0.3155, 0.3166, 0.3142],\n",
      "          [0.3158, 0.3169, 0.3154, 0.3161, 0.3165, 0.3150, 0.3143],\n",
      "          [0.3150, 0.3151, 0.3144, 0.3142, 0.3139, 0.3136, 0.3146],\n",
      "          [0.3143, 0.3151, 0.3144, 0.3145, 0.3152, 0.3150, 0.3144]],\n",
      "\n",
      "         [[0.2050, 0.2047, 0.2056, 0.2055, 0.2059, 0.2057, 0.2041],\n",
      "          [0.2052, 0.2052, 0.2054, 0.2058, 0.2057, 0.2055, 0.2052],\n",
      "          [0.2046, 0.2048, 0.2048, 0.2058, 0.2051, 0.2052, 0.2043],\n",
      "          [0.2043, 0.2050, 0.2049, 0.2045, 0.2047, 0.2056, 0.2035],\n",
      "          [0.2049, 0.2058, 0.2045, 0.2052, 0.2055, 0.2044, 0.2036],\n",
      "          [0.2042, 0.2043, 0.2037, 0.2036, 0.2034, 0.2031, 0.2038],\n",
      "          [0.2036, 0.2043, 0.2037, 0.2038, 0.2043, 0.2042, 0.2037]],\n",
      "\n",
      "         [[0.3159, 0.3156, 0.3167, 0.3166, 0.3171, 0.3167, 0.3148],\n",
      "          [0.3162, 0.3162, 0.3164, 0.3169, 0.3168, 0.3165, 0.3162],\n",
      "          [0.3154, 0.3157, 0.3155, 0.3168, 0.3160, 0.3162, 0.3151],\n",
      "          [0.3152, 0.3161, 0.3157, 0.3151, 0.3155, 0.3166, 0.3142],\n",
      "          [0.3158, 0.3169, 0.3154, 0.3161, 0.3165, 0.3150, 0.3143],\n",
      "          [0.3150, 0.3151, 0.3144, 0.3142, 0.3139, 0.3136, 0.3146],\n",
      "          [0.3143, 0.3151, 0.3144, 0.3145, 0.3152, 0.3150, 0.3144]],\n",
      "\n",
      "         [[0.0402, 0.0402, 0.0404, 0.0403, 0.0404, 0.0403, 0.0400],\n",
      "          [0.0403, 0.0402, 0.0403, 0.0404, 0.0403, 0.0403, 0.0403],\n",
      "          [0.0401, 0.0402, 0.0400, 0.0403, 0.0401, 0.0402, 0.0401],\n",
      "          [0.0401, 0.0403, 0.0401, 0.0400, 0.0400, 0.0403, 0.0399],\n",
      "          [0.0402, 0.0404, 0.0401, 0.0402, 0.0403, 0.0399, 0.0400],\n",
      "          [0.0400, 0.0401, 0.0399, 0.0399, 0.0398, 0.0398, 0.0400],\n",
      "          [0.0399, 0.0401, 0.0400, 0.0400, 0.0401, 0.0400, 0.0400]],\n",
      "\n",
      "         [[0.2281, 0.2279, 0.2292, 0.2287, 0.2292, 0.2286, 0.2266],\n",
      "          [0.2284, 0.2285, 0.2285, 0.2290, 0.2287, 0.2283, 0.2284],\n",
      "          [0.2276, 0.2279, 0.2266, 0.2284, 0.2272, 0.2284, 0.2275],\n",
      "          [0.2276, 0.2286, 0.2272, 0.2260, 0.2266, 0.2282, 0.2265],\n",
      "          [0.2278, 0.2292, 0.2274, 0.2277, 0.2284, 0.2259, 0.2268],\n",
      "          [0.2271, 0.2272, 0.2265, 0.2259, 0.2255, 0.2253, 0.2270],\n",
      "          [0.2266, 0.2275, 0.2266, 0.2266, 0.2277, 0.2271, 0.2268]],\n",
      "\n",
      "         [[0.3159, 0.3156, 0.3167, 0.3166, 0.3171, 0.3167, 0.3148],\n",
      "          [0.3162, 0.3162, 0.3164, 0.3169, 0.3168, 0.3165, 0.3162],\n",
      "          [0.3154, 0.3157, 0.3155, 0.3168, 0.3160, 0.3162, 0.3151],\n",
      "          [0.3152, 0.3161, 0.3157, 0.3151, 0.3155, 0.3166, 0.3142],\n",
      "          [0.3158, 0.3169, 0.3154, 0.3161, 0.3165, 0.3150, 0.3143],\n",
      "          [0.3150, 0.3151, 0.3144, 0.3142, 0.3139, 0.3136, 0.3146],\n",
      "          [0.3143, 0.3151, 0.3144, 0.3145, 0.3152, 0.3150, 0.3144]],\n",
      "\n",
      "         [[0.2281, 0.2279, 0.2292, 0.2287, 0.2292, 0.2286, 0.2266],\n",
      "          [0.2284, 0.2285, 0.2285, 0.2290, 0.2287, 0.2283, 0.2284],\n",
      "          [0.2276, 0.2279, 0.2266, 0.2284, 0.2272, 0.2284, 0.2275],\n",
      "          [0.2276, 0.2286, 0.2272, 0.2260, 0.2266, 0.2282, 0.2265],\n",
      "          [0.2278, 0.2292, 0.2274, 0.2277, 0.2284, 0.2259, 0.2268],\n",
      "          [0.2271, 0.2272, 0.2265, 0.2259, 0.2255, 0.2253, 0.2270],\n",
      "          [0.2266, 0.2275, 0.2266, 0.2266, 0.2277, 0.2271, 0.2268]],\n",
      "\n",
      "         [[0.2050, 0.2047, 0.2056, 0.2055, 0.2059, 0.2057, 0.2041],\n",
      "          [0.2052, 0.2052, 0.2054, 0.2058, 0.2057, 0.2055, 0.2052],\n",
      "          [0.2046, 0.2048, 0.2048, 0.2058, 0.2051, 0.2052, 0.2043],\n",
      "          [0.2043, 0.2050, 0.2049, 0.2045, 0.2047, 0.2056, 0.2035],\n",
      "          [0.2049, 0.2058, 0.2045, 0.2052, 0.2055, 0.2044, 0.2036],\n",
      "          [0.2042, 0.2043, 0.2037, 0.2036, 0.2034, 0.2031, 0.2038],\n",
      "          [0.2036, 0.2043, 0.2037, 0.2038, 0.2043, 0.2042, 0.2037]],\n",
      "\n",
      "         [[0.2050, 0.2047, 0.2056, 0.2055, 0.2059, 0.2057, 0.2041],\n",
      "          [0.2052, 0.2052, 0.2054, 0.2058, 0.2057, 0.2055, 0.2052],\n",
      "          [0.2046, 0.2048, 0.2048, 0.2058, 0.2051, 0.2052, 0.2043],\n",
      "          [0.2043, 0.2050, 0.2049, 0.2045, 0.2047, 0.2056, 0.2035],\n",
      "          [0.2049, 0.2058, 0.2045, 0.2052, 0.2055, 0.2044, 0.2036],\n",
      "          [0.2042, 0.2043, 0.2037, 0.2036, 0.2034, 0.2031, 0.2038],\n",
      "          [0.2036, 0.2043, 0.2037, 0.2038, 0.2043, 0.2042, 0.2037]],\n",
      "\n",
      "         [[0.0402, 0.0402, 0.0404, 0.0403, 0.0404, 0.0403, 0.0400],\n",
      "          [0.0403, 0.0402, 0.0403, 0.0404, 0.0403, 0.0403, 0.0403],\n",
      "          [0.0401, 0.0402, 0.0400, 0.0403, 0.0401, 0.0402, 0.0401],\n",
      "          [0.0401, 0.0403, 0.0401, 0.0400, 0.0400, 0.0403, 0.0399],\n",
      "          [0.0402, 0.0404, 0.0401, 0.0402, 0.0403, 0.0399, 0.0400],\n",
      "          [0.0400, 0.0401, 0.0399, 0.0399, 0.0398, 0.0398, 0.0400],\n",
      "          [0.0399, 0.0401, 0.0400, 0.0400, 0.0401, 0.0400, 0.0400]],\n",
      "\n",
      "         [[0.3159, 0.3156, 0.3167, 0.3166, 0.3171, 0.3167, 0.3148],\n",
      "          [0.3162, 0.3162, 0.3164, 0.3169, 0.3168, 0.3165, 0.3162],\n",
      "          [0.3154, 0.3157, 0.3155, 0.3168, 0.3160, 0.3162, 0.3151],\n",
      "          [0.3152, 0.3161, 0.3157, 0.3151, 0.3155, 0.3166, 0.3142],\n",
      "          [0.3158, 0.3169, 0.3154, 0.3161, 0.3165, 0.3150, 0.3143],\n",
      "          [0.3150, 0.3151, 0.3144, 0.3142, 0.3139, 0.3136, 0.3146],\n",
      "          [0.3143, 0.3151, 0.3144, 0.3145, 0.3152, 0.3150, 0.3144]],\n",
      "\n",
      "         [[0.0402, 0.0402, 0.0404, 0.0403, 0.0404, 0.0403, 0.0400],\n",
      "          [0.0403, 0.0402, 0.0403, 0.0404, 0.0403, 0.0403, 0.0403],\n",
      "          [0.0401, 0.0402, 0.0400, 0.0403, 0.0401, 0.0402, 0.0401],\n",
      "          [0.0401, 0.0403, 0.0401, 0.0400, 0.0400, 0.0403, 0.0399],\n",
      "          [0.0402, 0.0404, 0.0401, 0.0402, 0.0403, 0.0399, 0.0400],\n",
      "          [0.0400, 0.0401, 0.0399, 0.0399, 0.0398, 0.0398, 0.0400],\n",
      "          [0.0399, 0.0401, 0.0400, 0.0400, 0.0401, 0.0400, 0.0400]],\n",
      "\n",
      "         [[0.2281, 0.2279, 0.2292, 0.2287, 0.2292, 0.2286, 0.2266],\n",
      "          [0.2284, 0.2285, 0.2285, 0.2290, 0.2287, 0.2283, 0.2284],\n",
      "          [0.2276, 0.2279, 0.2266, 0.2284, 0.2272, 0.2284, 0.2275],\n",
      "          [0.2276, 0.2286, 0.2272, 0.2260, 0.2266, 0.2282, 0.2265],\n",
      "          [0.2278, 0.2292, 0.2274, 0.2277, 0.2284, 0.2259, 0.2268],\n",
      "          [0.2271, 0.2272, 0.2265, 0.2259, 0.2255, 0.2253, 0.2270],\n",
      "          [0.2266, 0.2275, 0.2266, 0.2266, 0.2277, 0.2271, 0.2268]],\n",
      "\n",
      "         [[0.2050, 0.2047, 0.2056, 0.2055, 0.2059, 0.2057, 0.2041],\n",
      "          [0.2052, 0.2052, 0.2054, 0.2058, 0.2057, 0.2055, 0.2052],\n",
      "          [0.2046, 0.2048, 0.2048, 0.2058, 0.2051, 0.2052, 0.2043],\n",
      "          [0.2043, 0.2050, 0.2049, 0.2045, 0.2047, 0.2056, 0.2035],\n",
      "          [0.2049, 0.2058, 0.2045, 0.2052, 0.2055, 0.2044, 0.2036],\n",
      "          [0.2042, 0.2043, 0.2037, 0.2036, 0.2034, 0.2031, 0.2038],\n",
      "          [0.2036, 0.2043, 0.2037, 0.2038, 0.2043, 0.2042, 0.2037]],\n",
      "\n",
      "         [[0.3159, 0.3156, 0.3167, 0.3166, 0.3171, 0.3167, 0.3148],\n",
      "          [0.3162, 0.3162, 0.3164, 0.3169, 0.3168, 0.3165, 0.3162],\n",
      "          [0.3154, 0.3157, 0.3155, 0.3168, 0.3160, 0.3162, 0.3151],\n",
      "          [0.3152, 0.3161, 0.3157, 0.3151, 0.3155, 0.3166, 0.3142],\n",
      "          [0.3158, 0.3169, 0.3154, 0.3161, 0.3165, 0.3150, 0.3143],\n",
      "          [0.3150, 0.3151, 0.3144, 0.3142, 0.3139, 0.3136, 0.3146],\n",
      "          [0.3143, 0.3151, 0.3144, 0.3145, 0.3152, 0.3150, 0.3144]],\n",
      "\n",
      "         [[0.0402, 0.0402, 0.0404, 0.0403, 0.0404, 0.0403, 0.0400],\n",
      "          [0.0403, 0.0402, 0.0403, 0.0404, 0.0403, 0.0403, 0.0403],\n",
      "          [0.0401, 0.0402, 0.0400, 0.0403, 0.0401, 0.0402, 0.0401],\n",
      "          [0.0401, 0.0403, 0.0401, 0.0400, 0.0400, 0.0403, 0.0399],\n",
      "          [0.0402, 0.0404, 0.0401, 0.0402, 0.0403, 0.0399, 0.0400],\n",
      "          [0.0400, 0.0401, 0.0399, 0.0399, 0.0398, 0.0398, 0.0400],\n",
      "          [0.0399, 0.0401, 0.0400, 0.0400, 0.0401, 0.0400, 0.0400]],\n",
      "\n",
      "         [[0.0402, 0.0402, 0.0404, 0.0403, 0.0404, 0.0403, 0.0400],\n",
      "          [0.0403, 0.0402, 0.0403, 0.0404, 0.0403, 0.0403, 0.0403],\n",
      "          [0.0401, 0.0402, 0.0400, 0.0403, 0.0401, 0.0402, 0.0401],\n",
      "          [0.0401, 0.0403, 0.0401, 0.0400, 0.0400, 0.0403, 0.0399],\n",
      "          [0.0402, 0.0404, 0.0401, 0.0402, 0.0403, 0.0399, 0.0400],\n",
      "          [0.0400, 0.0401, 0.0399, 0.0399, 0.0398, 0.0398, 0.0400],\n",
      "          [0.0399, 0.0401, 0.0400, 0.0400, 0.0401, 0.0400, 0.0400]]]],\n",
      "       grad_fn=<MkldnnConvolutionBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(resnet.layer4[0].downsample[0].X)\n",
    "print(resnet.layer4[0].downsample[0].Y)\n",
    "#print(R_list[-1][-1][0][0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
